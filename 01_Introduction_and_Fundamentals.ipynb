{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“š Notebook 01: Introduction and Fundamentals\n",
    "\n",
    "**LangChain 1.0.5+ | Mixed Level Class**\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will understand:\n",
    "1. What LangChain is and why it's useful\n",
    "2. LangChain's modular architecture\n",
    "3. Core concepts: Documents, Chains, and LCEL\n",
    "4. How to set up your development environment\n",
    "5. The difference between LangChain and traditional ML pipelines\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“– Table of Contents\n",
    "\n",
    "1. [What is LangChain?](#what-is-langchain)\n",
    "2. [LangChain Architecture](#architecture)\n",
    "3. [Environment Setup](#setup)\n",
    "4. [Core Concepts](#core-concepts)\n",
    "5. [Quick Start Example](#quick-start)\n",
    "6. [LangChain vs Traditional Pipelines](#comparison)\n",
    "7. [Summary & Next Steps](#summary)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"what-is-langchain\"></a>\n",
    "## 1. What is LangChain? ğŸ¤”\n",
    "\n",
    "### ğŸ”° BEGINNER SECTION\n",
    "\n",
    "**LangChain** is an open-source framework that makes it easy to build applications powered by Large Language Models (LLMs) like GPT-4, Claude, or Llama.\n",
    "\n",
    "### Why LangChain?\n",
    "\n",
    "Imagine you want to build a chatbot that can:\n",
    "- Answer questions about your company's PDF documents\n",
    "- Search through your database\n",
    "- Remember previous conversations\n",
    "- Call external APIs\n",
    "\n",
    "Without LangChain, you'd need to:\n",
    "1. âœï¸ Write code to load and parse PDFs\n",
    "2. âœï¸ Convert text to embeddings\n",
    "3. âœï¸ Store embeddings in a vector database\n",
    "4. âœï¸ Implement semantic search\n",
    "5. âœï¸ Format prompts for the LLM\n",
    "6. âœï¸ Handle LLM API calls\n",
    "7. âœï¸ Manage conversation memory\n",
    "\n",
    "**With LangChain:**\n",
    "- âœ… All these components are pre-built and ready to use\n",
    "- âœ… You just connect them like LEGO blocks\n",
    "- âœ… Focus on your application logic, not infrastructure\n",
    "\n",
    "### ğŸ“ INTERMEDIATE NOTE\n",
    "\n",
    "LangChain provides:\n",
    "- **Abstractions**: Unified interfaces for different LLMs, vector stores, and tools\n",
    "- **Chains**: Composable workflows using LCEL (LangChain Expression Language)\n",
    "- **Agents**: Autonomous systems that can use tools and make decisions\n",
    "- **Memory**: Conversation history and context management\n",
    "- **Callbacks**: Monitoring, logging, and debugging hooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"architecture\"></a>\n",
    "## 2. LangChain Architecture ğŸ—ï¸\n",
    "\n",
    "### ğŸ”° BEGINNER: Visual Architecture\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    YOUR APPLICATION                     â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                           â†“\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                  LANGCHAIN FRAMEWORK                    â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚\n",
    "â”‚  â”‚ Document â”‚  â”‚   Text   â”‚  â”‚ Embeddingsâ”‚  â”‚ Vector  â”‚ â”‚\n",
    "â”‚  â”‚ Loaders  â”‚â†’ â”‚ Splittersâ”‚â†’ â”‚  Models   â”‚â†’ â”‚ Stores  â”‚ â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚\n",
    "â”‚                                                         â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚\n",
    "â”‚  â”‚Retrieversâ”‚  â”‚ Prompts  â”‚  â”‚   LLMs   â”‚               â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚\n",
    "â”‚                                                         â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚\n",
    "â”‚  â”‚         LCEL (LangChain Expression Language)     â”‚   â”‚\n",
    "â”‚  â”‚         Connects everything with | operator      â”‚   â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                           â†“\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚             EXTERNAL SERVICES & DATA                    â”‚\n",
    "â”‚  â€¢ OpenAI/Anthropic APIs  â€¢ Vector Databases            â”‚\n",
    "â”‚  â€¢ PDF Files              â€¢ Websites                    â”‚\n",
    "â”‚  â€¢ Databases              â€¢ APIs                        â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### ğŸ“ INTERMEDIATE: Package Structure (LangChain 1.0+)\n",
    "\n",
    "LangChain is organized into several packages:\n",
    "\n",
    "| Package | Purpose | Example Imports |\n",
    "|---------|---------|------------------|\n",
    "| **langchain-core** | Core abstractions, base classes | `from langchain_core.documents import Document` |\n",
    "| **langchain-community** | Community integrations (loaders, vector stores) | `from langchain_community.document_loaders import PyPDFLoader` |\n",
    "| **langchain-openai** | OpenAI-specific integrations | `from langchain_openai import ChatOpenAI, OpenAIEmbeddings` |\n",
    "| **langchain-text-splitters** | Text splitting utilities | `from langchain_text_splitters import RecursiveCharacterTextSplitter` |\n",
    "\n",
    "**Why this matters:** In LangChain 1.0+, you import from specific packages instead of `langchain` directly. This reduces dependencies and improves modularity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"setup\"></a>\n",
    "## 3. Environment Setup ğŸ› ï¸\n",
    "\n",
    "### ğŸ”° BEGINNER: Step-by-Step Setup\n",
    "\n",
    "Let's verify your environment is ready!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.13.2 (main, Mar 17 2025, 21:04:07) [MSC v.1943 64 bit (AMD64)]\n",
      "âœ… Python version is compatible\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Check Python version (should be 3.9+)\n",
    "import sys\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "# Check if Python is 3.9 or higher\n",
    "if sys.version_info >= (3, 9):\n",
    "    print(\"âœ… Python version is compatible\")\n",
    "else:\n",
    "    print(\"âŒ Please upgrade to Python 3.9 or higher\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain version: 1.1.0\n",
      "LangChain Core version: 1.1.0\n",
      "âœ… LangChain 1.0+ detected\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Import LangChain and check version\n",
    "import langchain\n",
    "from langchain_core import __version__ as core_version\n",
    "\n",
    "print(f\"LangChain version: {langchain.__version__}\")\n",
    "print(f\"LangChain Core version: {core_version}\")\n",
    "\n",
    "# We're using LangChain 1.0.5+ for this course\n",
    "if langchain.__version__ >= \"1.0\":\n",
    "    print(\"âœ… LangChain 1.0+ detected\")\n",
    "else:\n",
    "    print(\"âŒ Please upgrade: pip install --upgrade langchain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… OPENAI_API_KEY found\n",
      "âœ… GOOGLE_API_KEY found\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Load environment variables (API keys)\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Check if OpenAI API key is set\n",
    "# NOTE: We don't print the actual key for security!\n",
    "if os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"âœ… OPENAI_API_KEY found\")\n",
    "else:\n",
    "    print(\"âŒ OPENAI_API_KEY not found\")\n",
    "    print(\"   Create a .env file with: OPENAI_API_KEY=your-key-here\")\n",
    "\n",
    "# Check for Google API key (optional, for Google Gemini)\n",
    "if os.getenv(\"GOOGLE_API_KEY\"):\n",
    "    print(\"âœ… GOOGLE_API_KEY found\")\n",
    "else:\n",
    "    print(\"âš ï¸  GOOGLE_API_KEY not found (optional for this notebook)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“ Setting Up Your .env File\n",
    "\n",
    "If you don't have a `.env` file, create one in the project root:\n",
    "\n",
    "```bash\n",
    "# .env file\n",
    "OPENAI_API_KEY=sk-proj-your-key-here\n",
    "GOOGLE_API_KEY=your-google-key-here\n",
    "```\n",
    "\n",
    "**âš ï¸ SECURITY WARNING:**\n",
    "- Never commit `.env` files to Git\n",
    "- Add `.env` to your `.gitignore` file\n",
    "- Never hardcode API keys in your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"core-concepts\"></a>\n",
    "## 4. Core Concepts ğŸ“š\n",
    "\n",
    "### 4.1 Documents ğŸ“„\n",
    "\n",
    "### ğŸ”° BEGINNER\n",
    "\n",
    "A **Document** is LangChain's way of representing a piece of text with metadata.\n",
    "\n",
    "Think of it like a note card:\n",
    "- **Front (page_content):** The actual text\n",
    "- **Back (metadata):** Information about the text (source, page number, date, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content:\n",
      "LangChain makes building LLM applications easy!\n",
      "\n",
      "Metadata:\n",
      "{'source': 'introduction.txt', 'author': 'LangChain Team', 'date': '2025-01-15'}\n",
      "\n",
      "Source: introduction.txt\n"
     ]
    }
   ],
   "source": [
    "# Creating a Document manually\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Create a simple document\n",
    "doc = Document(\n",
    "    page_content=\"LangChain makes building LLM applications easy!\",\n",
    "    metadata={\n",
    "        \"source\": \"introduction.txt\",\n",
    "        \"author\": \"LangChain Team\",\n",
    "        \"date\": \"2025-01-15\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Access the content\n",
    "print(\"Content:\")\n",
    "print(doc.page_content)\n",
    "print(\"\\nMetadata:\")\n",
    "print(doc.metadata)\n",
    "print(f\"\\nSource: {doc.metadata['source']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“ INTERMEDIATE: Why Metadata Matters\n",
    "\n",
    "Metadata is crucial for:\n",
    "1. **Citation**: Showing users where information came from\n",
    "2. **Filtering**: Only search documents from specific sources\n",
    "3. **Debugging**: Tracking which documents are being retrieved\n",
    "4. **Analytics**: Understanding which sources are most useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“„ Document 1:\n",
      "   Content: Python is a high-level programming language.\n",
      "   Category: programming\n",
      "   Difficulty: beginner\n",
      "\n",
      "ğŸ“„ Document 2:\n",
      "   Content: Machine learning is a subset of artificial intelligence.\n",
      "   Category: AI\n",
      "   Difficulty: intermediate\n",
      "\n",
      "ğŸ“„ Document 3:\n",
      "   Content: RAG combines retrieval and generation for better LLM outputs.\n",
      "   Category: AI\n",
      "   Difficulty: advanced\n"
     ]
    }
   ],
   "source": [
    "# Creating multiple documents (like a mini knowledge base)\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=\"Python is a high-level programming language.\",\n",
    "        metadata={\"category\": \"programming\", \"difficulty\": \"beginner\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Machine learning is a subset of artificial intelligence.\",\n",
    "        metadata={\"category\": \"AI\", \"difficulty\": \"intermediate\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"RAG combines retrieval and generation for better LLM outputs.\",\n",
    "        metadata={\"category\": \"AI\", \"difficulty\": \"advanced\"}\n",
    "    )\n",
    "]\n",
    "\n",
    "# Print all documents\n",
    "for i, doc in enumerate(documents, 1):\n",
    "    print(f\"\\nğŸ“„ Document {i}:\")\n",
    "    print(f\"   Content: {doc.page_content}\")\n",
    "    print(f\"   Category: {doc.metadata['category']}\")\n",
    "    print(f\"   Difficulty: {doc.metadata['difficulty']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 LCEL (LangChain Expression Language) ğŸ”—\n",
    "\n",
    "### ğŸ”° BEGINNER\n",
    "\n",
    "**LCEL** is a way to connect different components using the pipe operator `|`.\n",
    "\n",
    "Think of it like a factory assembly line:\n",
    "```\n",
    "Input â†’ Component 1 â†’ Component 2 â†’ Component 3 â†’ Output\n",
    "```\n",
    "\n",
    "### Before LCEL (Old Way - Messy!):\n",
    "```python\n",
    "output = component3(component2(component1(input)))\n",
    "```\n",
    "\n",
    "### With LCEL (New Way - Clean!):\n",
    "```python\n",
    "chain = component1 | component2 | component3\n",
    "output = chain.invoke(input)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“ INTERMEDIATE: LCEL Deep Dive\n",
    "\n",
    "LCEL provides:\n",
    "- **Streaming**: Stream outputs as they're generated\n",
    "- **Batch Processing**: Process multiple inputs efficiently\n",
    "- **Async Support**: Non-blocking operations\n",
    "- **Debugging**: Better error messages and logging\n",
    "- **Type Safety**: Better IDE autocomplete\n",
    "\n",
    "**Key Methods:**\n",
    "- `.invoke(input)`: Process single input\n",
    "- `.batch([input1, input2])`: Process multiple inputs\n",
    "- `.stream(input)`: Stream output tokens\n",
    "- `.ainvoke(input)`: Async version of invoke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 'hello langchain'\n",
      "\n",
      "Processing:\n",
      "  Step 1: uppercase â†’ HELLO LANGCHAIN\n",
      "  Step 2: add_prefix â†’ RESULT: HELLO LANGCHAIN\n",
      "  Step 3: add_emoji â†’ âœ… RESULT: HELLO LANGCHAIN\n",
      "\n",
      "Final Output: âœ… RESULT: HELLO LANGCHAIN\n"
     ]
    }
   ],
   "source": [
    "# Simple LCEL Example: String Transformation Chain\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# Create simple transformation functions\n",
    "def uppercase(text: str) -> str:\n",
    "    \"\"\"Convert text to uppercase\"\"\"\n",
    "    print(f\"  Step 1: uppercase â†’ {text.upper()}\")\n",
    "    return text.upper()\n",
    "\n",
    "def add_prefix(text: str) -> str:\n",
    "    \"\"\"Add a prefix to text\"\"\"\n",
    "    result = f\"RESULT: {text}\"\n",
    "    print(f\"  Step 2: add_prefix â†’ {result}\")\n",
    "    return result\n",
    "\n",
    "def add_emoji(text: str) -> str:\n",
    "    \"\"\"Add emoji to text\"\"\"\n",
    "    result = f\"âœ… {text}\"\n",
    "    print(f\"  Step 3: add_emoji â†’ {result}\")\n",
    "    return result\n",
    "\n",
    "# Create runnables (components that can be chained)\n",
    "uppercase_runnable = RunnableLambda(uppercase)\n",
    "prefix_runnable = RunnableLambda(add_prefix)\n",
    "emoji_runnable = RunnableLambda(add_emoji)\n",
    "\n",
    "# Build the chain using LCEL\n",
    "chain = uppercase_runnable | prefix_runnable | emoji_runnable\n",
    "\n",
    "# Execute the chain\n",
    "print(\"Input: 'hello langchain'\")\n",
    "print(\"\\nProcessing:\")\n",
    "result = chain.invoke(\"hello langchain\")\n",
    "print(f\"\\nFinal Output: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Chains ğŸ”—\n",
    "\n",
    "### ğŸ”° BEGINNER\n",
    "\n",
    "A **Chain** is a sequence of operations. Common chain types:\n",
    "\n",
    "1. **Simple Chain**: Input â†’ Process â†’ Output\n",
    "2. **RAG Chain**: Query â†’ Retrieve â†’ Generate â†’ Answer\n",
    "3. **Multi-step Chain**: Input â†’ Step 1 â†’ Step 2 â†’ Step 3 â†’ Output\n",
    "\n",
    "We'll build complex chains in later notebooks!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"quick-start\"></a>\n",
    "## 5. Quick Start Example ğŸš€\n",
    "\n",
    "### ğŸ”° BEGINNER: Your First LLM Call\n",
    "\n",
    "Let's make our first call to an LLM using LangChain!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is LangChain in one sentence?\n",
      "\n",
      "Answer: LangChain is a development framework that helps build applications powered by large language models (LLMs) by enabling them to connect with external data sources and tools, and chain together complex operations.\n"
     ]
    }
   ],
   "source": [
    "# Gemini \n",
    "# pip install -U langchain-google-genai\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "model=\"gemini-2.5-flash\",  # Example Gemini model\n",
    "temperature=0  # Deterministic outputs for learning\n",
    ")\n",
    "\n",
    "# Make a simple call\n",
    "response = llm.invoke(\"What is LangChain in one sentence?\")\n",
    "\n",
    "# Print the response\n",
    "print(\"Question: What is LangChain in one sentence?\")\n",
    "print(f\"\\nAnswer: {response.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is LangChain in two sentences?\n",
      "\n",
      "Answer: LangChain is a framework for building AI-powered applications around language models, offering reusable building blocks like prompts, chains, agents, and memory to manage conversations and reasoning. It enables connecting LLMs to external tools, APIs, and data sources to orchestrate multi-step workflows and tool use for complex tasks.\n"
     ]
    }
   ],
   "source": [
    "# Import ChatOpenAI (the LLM interface)\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Initialize the LLM\n",
    "# model: Which GPT model to use\n",
    "# temperature: 0 = deterministic, 1 = creative\n",
    "llm = ChatOpenAI(\n",
    "    #model=\"gpt-3.5-turbo\",  # Cheaper, faster model for learning\n",
    "    model=\"gpt-5-nano\",  # Cheaper, faster model for learning\n",
    "    temperature=0  # Deterministic outputs for learning\n",
    ")\n",
    "\n",
    "# Make a simple call\n",
    "response = llm.invoke(\"What is LangChain in two sentences?\")\n",
    "\n",
    "# Print the response\n",
    "print(\"Question: What is LangChain in two sentences?\")\n",
    "print(f\"\\nAnswer: {response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“ INTERMEDIATE: Understanding the Response Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Type: <class 'langchain_core.messages.ai.AIMessage'>\n",
      "\n",
      "Content: LangChain is a decentralized language learning platform that uses blockchain technology to connect language learners with native speakers for personalized language exchange.\n",
      "\n",
      "Response Metadata:\n",
      "{'token_usage': {'completion_tokens': 24, 'prompt_tokens': 15, 'total_tokens': 39, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CgafdAxmMs584ephvr033GKqZ9L1S', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}\n",
      "\n",
      "Tokens Used:\n",
      "  Prompt: 15\n",
      "  Completion: 24\n",
      "  Total: 39\n"
     ]
    }
   ],
   "source": [
    "# The response is an AIMessage object with metadata\n",
    "print(\"Response Type:\", type(response))\n",
    "print(\"\\nContent:\", response.content)\n",
    "print(\"\\nResponse Metadata:\")\n",
    "print(response.response_metadata)\n",
    "\n",
    "# Access specific metadata\n",
    "if 'token_usage' in response.response_metadata:\n",
    "    usage = response.response_metadata['token_usage']\n",
    "    print(f\"\\nTokens Used:\")\n",
    "    print(f\"  Prompt: {usage.get('prompt_tokens', 'N/A')}\")\n",
    "    print(f\"  Completion: {usage.get('completion_tokens', 'N/A')}\")\n",
    "    print(f\"  Total: {usage.get('total_tokens', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ”° BEGINNER: Using Prompts\n",
    "\n",
    "Instead of plain strings, use **prompt templates** for better control:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt Template:\n",
      "Explain {topic} in simple terms suitable for beginners.\n",
      "prompt: input_variables=['topic'] input_types={} partial_variables={} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, template='Explain {topic} in simple terms suitable for beginners.'), additional_kwargs={})]\n",
      "prompt.input_variables: ['topic']\n",
      "prompt.input_types: {}\n",
      "prompt.partial_variables: {}\n",
      "prompt.messages: [HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, template='Explain {topic} in simple terms suitable for beginners.'), additional_kwargs={})]\n",
      "prompt.messages[0]: prompt=PromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, template='Explain {topic} in simple terms suitable for beginners.') additional_kwargs={}\n",
      "prompt.messages[0].prompt: input_variables=['topic'] input_types={} partial_variables={} template='Explain {topic} in simple terms suitable for beginners.'\n",
      "prompt.messages[0].prompt.template: Explain {topic} in simple terms suitable for beginners.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Create a prompt template\n",
    "# {topic} is a variable we'll fill in later\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Explain {topic} in simple terms suitable for beginners.\"\n",
    ")\n",
    "\n",
    "# View the prompt structure\n",
    "print(\"Prompt Template:\")\n",
    "print(prompt.messages[0].prompt.template)\n",
    "print(f\"prompt: {prompt}\")\n",
    "print(f\"prompt.input_variables: {prompt.input_variables}\")\n",
    "print(f\"prompt.input_types: {prompt.input_types}\")\n",
    "print(f\"prompt.partial_variables: {prompt.partial_variables}\")\n",
    "print(f\"prompt.messages: {prompt.messages}\")\n",
    "print(f\"prompt.messages[0]: {prompt.messages[0]}\")\n",
    "print(f\"prompt.messages[0].prompt: {prompt.messages[0].prompt}\")\n",
    "print(f\"prompt.messages[0].prompt.template: {prompt.messages[0].prompt.template}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Topic: MACHINE LEARNING\n",
      "============================================================\n",
      "Hereâ€™s a simple, beginner-friendly way to understand machine learning (ML).\n",
      "\n",
      "- The basic idea\n",
      "  - ML is a way for computers to learn patterns from data. Instead of giving a computer every rule, you give it examples, and it learns how to make good guesses on its own.\n",
      "\n",
      "- Key terms\n",
      "  - Data: the examples you give the computer (could be numbers, pictures, text, etc.).\n",
      "  - Features: the parts of the data you use to describe each example (for a house price predictor, features might be size, location, and number of bedrooms).\n",
      "  - Label: the answer you want the computer to predict (for house prices, the actual price).\n",
      "  - Model: the â€œrecipeâ€ or rulebook the computer uses to turn features into a prediction.\n",
      "  - Training: showing the model many examples so it can learn the rule.\n",
      "  - Prediction: the modelâ€™s guess for a new, unseen example.\n",
      "\n",
      "- The main types, in simple terms\n",
      "  - Supervised learning: you give the computer lots of examples with the right answers (features -> label). It learns to map features to labels. Examples: predicting house prices, filtering spam, recognizing handwritten digits.\n",
      "  - Unsupervised learning: you give the computer data without labels and it finds patterns on its own. Examples: grouping similar customers, compressing data, finding unusual items.\n",
      "  - Reinforcement learning: the computer learns by trying actions in an environment and getting feedback (rewards or penalties). Itâ€™s like learning to play a game by trial and error.\n",
      "\n",
      "- How it works, in a nutshell\n",
      "  1. Collect data (examples with features and, if supervised, the correct label).\n",
      "  2. Choose a model (a simple rule or a more complex one).\n",
      "  3. Train the model by showing many examples and adjusting the rule so predictions get closer to the true answers.\n",
      "  4. Check how well it does on new data it hasnâ€™t seen (tests or a separate dataset).\n",
      "  5. If needed, tweak things or get more data to improve performance.\n",
      "\n",
      "- A simple everyday example\n",
      "  - Spam filtering:\n",
      "    - Features: words in an email, sender, etc.\n",
      "    - Label: is this email spam or not?\n",
      "    - Model learns to look at the features and predict spam. After training on many emails, it can guess whether a new email is likely spam.\n",
      "\n",
      "- A tiny house-pricing example (very high level)\n",
      "  - Features: size, location, age of the house\n",
      "  - Label: the price\n",
      "  - The model learns how size, location, and age typically relate to price, so it can estimate a price for a new house.\n",
      "\n",
      "- Common ideas and caveats\n",
      "  - Overfitting: a model that learns the training examples too well and doesnâ€™t do well on new data.\n",
      "  - Generalization: how well the model makes good predictions on new, unseen data.\n",
      "  - Data quality matters: garbage in, garbage out. If the data is messy or biased, the model can be too.\n",
      "  - No magic â€œone-size-fits-allâ€ solution: different problems need different models and features.\n",
      "\n",
      "- Quick glossary\n",
      "  - Features: measurable inputs describing an example.\n",
      "  - Label: the correct answer you want to predict.\n",
      "  - Training: teaching the model by showing it data with answers.\n",
      "  - Prediction: the modelâ€™s guess for a new example.\n",
      "  - Model: the algorithmâ€™s internal rules for turning features into predictions.\n",
      "\n",
      "If youâ€™d like, I can walk through a very small, concrete example step by step with simple numbers, or pick a beginner-friendly dataset and show a tiny end-to-end outline.\n",
      "\n",
      "============================================================\n",
      "Topic: EMBEDDINGS\n",
      "============================================================\n",
      "Embeddings are a simple, friendly idea often used in language and other data: turning things into points in a space so that similar things sit near each other.\n",
      "\n",
      "In plain terms\n",
      "- Think of each word (or item) as a dot placed in a big space.\n",
      "- The position of that dot is a set of numbers (a vector).\n",
      "- Words that are similar in meaning or use end up close to each other in that space.\n",
      "- The space is learned from lots of data, so it captures patterns like which words tend to appear together.\n",
      "\n",
      "Why we use embeddings\n",
      "- Computers work with numbers. Embeddings turn words (which are categorical) into numbers the computer can work with.\n",
      "- They are dense. Instead of a long, sparse one-hot vector, embeddings use a short, information-packed vector (like 50, 100, or 300 numbers long).\n",
      "- They make it easy to measure similarity (how close two words are) and to feed language into machine learning models.\n",
      "\n",
      "How embeddings are learned (at a high level)\n",
      "- You start with a lot of text (or other data).\n",
      "- The system tries to predict something about nearby words or items (for words, this might be predicting context words from a target word, or vice versa).\n",
      "- Through this learning, each word gets a vector. Words that often appear in similar contexts end up with similar vectors.\n",
      "- The result is a map where distances and directions encode relationships.\n",
      "\n",
      "Quick, beginner-friendly examples\n",
      "- Similar words sit near each other: cat and dog are close because theyâ€™re both animals; car might be far away from cat.\n",
      "- Simple arithmetic thatâ€™s often cited: vector(\"king\") - vector(\"man\") + vector(\"woman\") is close to vector(\"queen\"). The exact numbers arenâ€™t human-readable, but the idea is that the space captures meaningful relationships.\n",
      "\n",
      "What â€œembeddingsâ€ can apply to besides words\n",
      "- Words, sentences, or documents (sentence embeddings).\n",
      "- Images, music, users, productsâ€”anything you can put a vector on.\n",
      "- The idea stays the same: each item gets a numerical vector so models can reason about similarity and structure.\n",
      "\n",
      "How you use embeddings in practice\n",
      "- Start with pre-trained embeddings (many exist for words). Theyâ€™re ready-made and work well for many tasks.\n",
      "- Or train your own embeddings on your data if you have a specific domain.\n",
      "- Use the vectors as inputs to machine learning models, or compute similarities to find related items (nearest neighbors in the embedding space).\n",
      "\n",
      "Things to keep in mind\n",
      "- The meaning captured by embeddings depends on the data you train them on. If the data has biases, the embeddings can reflect them.\n",
      "- The number of dimensions (the length of the vector) is a design choice. Too few and you lose information; too many and the model can overfit or be harder to train.\n",
      "- The dimensions themselves arenâ€™t always interpretable by humans; theyâ€™re latent features discovered by the learning process.\n",
      "\n",
      "If youâ€™d like, I can give a tiny, concrete example with a couple of words and show what a simple 2D embedding might look like (purely illustrative), or point you to beginner-friendly tutorials and tools you can try.\n",
      "\n",
      "============================================================\n",
      "Topic: VECTOR DATABASES\n",
      "============================================================\n",
      "A vector database is a storage system that keeps data as mathematical vectors (lists of numbers) and lets you find items by how similar they are, not by exact text or keywords.\n",
      "\n",
      "Key ideas in simple terms\n",
      "\n",
      "- Vectors and embeddings: An embedding is a way to turn something like a sentence, a movie description, or an image into a list of numbers (a vector) that captures its meaning or content. Similar things end up with similar vectors.\n",
      "- What a vector database does: It stores lots of these vectors and can quickly find which vectors are most like a given query vector.\n",
      "- Why itâ€™s different from a regular database: Regular databases look up exact matches or numeric values in fixed fields. A vector database looks for semantic similarityâ€”things that feel â€œthe same ideaâ€ even if the wording is different.\n",
      "\n",
      "How it works at a high level\n",
      "\n",
      "1) Turn data into vectors: Use a machine learning model to convert items (texts, images, audio, etc.) into vectors.\n",
      "2) Store vectors with IDs: Put these vectors in the database, usually along with a way to identify the original item.\n",
      "3) Search by similarity: When you have a query (also turned into a vector), the database finds the items whose vectors are close to the query vector.\n",
      "4) Return results: Show the most similar items to you, often with a relevance score.\n",
      "\n",
      "How a vector search is measured\n",
      "\n",
      "- Similarity measures: The system compares vectors using math like cosine similarity (how aligned the directions are), dot product, or simple distance (Euclidean). Cosine similarity is popular because it focuses on the angle between vectors, not their length.\n",
      "- Exact vs approximate search: Exact nearest-neighbor search can be slow for lots of vectors. Most systems use approximate nearest neighbors (ANN) to get fast results with a tiny bit of trade-off in accuracy. For many applications, that trade-off is fine.\n",
      "\n",
      "Common use cases\n",
      "\n",
      "- Semantic search: Get documents that are about the same ideas even if they donâ€™t have the same exact words.\n",
      "- Recommendations: Find items similar to what a user liked (movies, products, songs).\n",
      "- Image or video similarity: Find visually similar images or clips.\n",
      "- Question-answering: Retrieve relevant passages that match the meaning of a question, not just matching keywords.\n",
      "\n",
      "Simple analogy\n",
      "\n",
      "Think of a huge library where instead of indexing books by exact words on the spine, you assign each book a â€œtopic vector.â€ If you ask for â€œbooks about friendship in stories,â€ the system finds books whose topic vectors sit near that concept, even if the exact phrases are different.\n",
      "\n",
      "A tiny example scenario\n",
      "\n",
      "- You have movie descriptions. You turn each description into an embedding (a vector).\n",
      "- A user types: â€œa funny coming-of-age story set at a music festival.â€\n",
      "- The system converts that query into a vector and looks for movie embeddings that are close to it.\n",
      "- It returns the most similar movies, even if those movies donâ€™t use the exact same words as the query.\n",
      "\n",
      "What you need to build a simple vector DB app\n",
      "\n",
      "- A way to make embeddings: use a pre-trained model (for text, models like sentence transformers; for images, a vision model).\n",
      "- A vector store: a database designed for vectors (examples you might hear about include Pinecone, Weaviate, Vespa, or building with FAISS/Annoy/ScaNN libraries).\n",
      "- A place to keep the original items: you can store the actual text, image, or link beside the vector, so you can display results.\n",
      "- An API or interface: a way to insert data (add/update) and to query (do similarity search).\n",
      "\n",
      "Pros and cons (quick view)\n",
      "\n",
      "- Pros:\n",
      "  - Finds semantically similar items, not just exact words.\n",
      "  - Scales to very large collections with fast approximate search.\n",
      "  - Flexible for text, images, audio, and more.\n",
      "- Cons:\n",
      "  - Requires good embeddings; results depend on the model quality.\n",
      "  - More complex setup than a simple keyword database.\n",
      "  - Might require extra memory and cost for large datasets.\n",
      "  - Not ideal for exact-match text tasks unless combined with keyword search.\n",
      "\n",
      "Quick-start outline\n",
      "\n",
      "- Pick a data type (text, images, etc.) and a corresponding embedding model.\n",
      "- Choose a vector store (and decide if you want exact or approximate search).\n",
      "- Compute embeddings for all items and store them with IDs in the vector store.\n",
      "- When a user queries, compute the query embedding and run a near-neighbor search.\n",
      "- Retrieve the matching items, optionally re-rank with additional signals (e.g., freshness, popularity).\n",
      "\n",
      "Common tools you might hear about (for beginners)\n",
      "\n",
      "- Libraries for embeddings: various open models like sentence-transformers for text, or image models for pictures.\n",
      "- Vector stores and engines: Pinecone, Weaviate, Vespa (cloud or self-hosted options); libraries like FAISS, Annoy, or ScaNN for building your own index.\n",
      "- Often, teams use a combination: embeddings to vectors plus a vector store for search, and a regular database or data store for the original content.\n",
      "\n",
      "If you want, tell me your data type (text articles, product descriptions, images, etc.) and your goals (semantic search, recommendations, etc.), and I can sketch a simple, concrete setup and step-by-step plan.\n"
     ]
    }
   ],
   "source": [
    "# Build a chain: Prompt â†’ LLM\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Components:\n",
    "# 1. prompt: Formats the input\n",
    "# 2. llm: Generates the response\n",
    "# 3. StrOutputParser: Extracts just the text from the response\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Use the chain with different topics\n",
    "topics = [\"machine learning\", \"embeddings\", \"vector databases\"]\n",
    "\n",
    "for topic in topics:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Topic: {topic.upper()}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    # Invoke the chain\n",
    "    explanation = chain.invoke({\"topic\": topic})\n",
    "    print(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Topic: MACHINE LEARNING\n",
      "============================================================\n",
      "Streaming Output:\n",
      "\n",
      "Machine learning is a way to teach computers to make guesses or decisions by learning from data, not by being told exact rules.\n",
      "\n",
      "Hereâ€™s a simple way to think about it:\n",
      "\n",
      "- You show the computer lots of examples that include the right answer. For example, you show many emails labeled â€œspamâ€ or â€œnot spam.â€\n",
      "- The computer looks for patterns in those examples (which words or features tend to appear in spam).\n",
      "- After learning from enough examples, the computer can guess the label for new, unseen inputs (predict whether a new email is spam).\n",
      "\n",
      "Key ideas\n",
      "\n",
      "- Data and labels: Data are the things you look at (emails, pictures, numbers). Labels are the answers you already know for those examples (spam/not spam, cat/not cat).\n",
      "- Model: A mathematical rule or function that the computer uses to make predictions.\n",
      "- Training: The process of adjusting the modelâ€™s internal settings so its predictions match the known labels as closely as possible.\n",
      "- Generalization: The modelâ€™s ability to make good predictions on new data, not just the data it was trained on.\n",
      "- Evaluation: Checking how well the model works on new data (usually held-out data you didnâ€™t use for training).\n",
      "\n",
      "Types of machine learning (in plain terms)\n",
      "\n",
      "- Supervised learning: You train the model with labeled examples. Tasks include\n",
      "  - Classification: putting something into categories (spam vs not spam, dog vs cat).\n",
      "  - Regression: predicting a number (house prices, temperature).\n",
      "- Unsupervised learning: The data donâ€™t have labels. The model tries to find structure on its own. Tasks include\n",
      "  - Clustering: grouping similar items together (customer segments).\n",
      "  - Dimensionality reduction: simplifying data while preserving important information.\n",
      "- Reinforcement learning: An agent learns by trying actions and seeing what happens, aiming to get rewards over time (video game playing, robot navigation).\n",
      "\n",
      "Very small example: spam filter\n",
      "- Data: emails labeled as \"spam\" or \"not spam.\"\n",
      "- Model learns patterns from those labels.\n",
      "- New emails get a spam score or a yes/no spam decision.\n",
      "- If it makes mistakes, you can retrain with more examples or adjust the model.\n",
      "\n",
      "What youâ€™d typically do to start\n",
      "\n",
      "- Collect data relevant to a problem you care about.\n",
      "- Choose a simple model and train it on your data.\n",
      "- Split data into training and testing sets to see how well it generalizes.\n",
      "- Evaluate performance with simple metrics (accuracy, error rate).\n",
      "- Iterate: try different models, add more data, or clean the data.\n",
      "\n",
      "Common pitfalls to know\n",
      "\n",
      "- Bad data quality or biased data leads to poor or unfair models.\n",
      "- Overfitting: the model learns the training data too well and fails on new data.\n",
      "- Privacy and security: be careful with sensitive data and how models might reveal it.\n",
      "\n",
      "If youâ€™re curious to try hands-on, start with beginner-friendly tutorials and datasets (for example, small classification tasks with scikit-learn in Python, or interactive notebooks that walk you through training a basic classifier). The idea is simple: give the computer examples, let it learn patterns, and then use what it learned to make predictions on new data.\n",
      "\n",
      "\n",
      "============================================================\n",
      "Topic: EMBEDDINGS\n",
      "============================================================\n",
      "Streaming Output:\n",
      "\n",
      "Embeddings are a way to turn things (like words, items, or users) into numbers so computers can work with them easily. Theyâ€™re not just random numbersâ€”nearby vectors mean â€œsimilarâ€ in a meaningful way.\n",
      "\n",
      "Simple analogy:\n",
      "- Imagine each word gets a fingerprint in a big space. Words with similar meanings or uses end up with fingerprints that are close to each other. So â€œcatâ€ and â€œdogâ€ are near, while â€œcatâ€ and â€œcarâ€ are farther apart.\n",
      "\n",
      "Key ideas in plain language:\n",
      "- A vector: an embedding is a list of numbers (a vector). The length of that list is called the dimensionality (e.g., 50, 100, or 300 numbers long).\n",
      "- Similarity: to see how similar two things are, we look at how close their vectors are. A common way is cosine similarity (how aligned the directions are) or simple distance.\n",
      "- Learned from data: the numbers are learned from lots of examples. For words, models look at how words appear near each other in text and adjust the vectors so that similar contexts have similar vectors.\n",
      "\n",
      "How embeddings are made (at a high level):\n",
      "- You gather lots of data (text, product views, user interactions, etc.).\n",
      "- A model is trained to predict or relate items to each other. In doing so, it assigns each item a vector.\n",
      "- After training, you can compare vectors to find similar items, or feed them into other models.\n",
      "\n",
      "What you can do with embeddings:\n",
      "- Find similar items: \"find words/products/users that are similar.\"\n",
      "- Measure similarity: compare two words to see how alike they are.\n",
      "- Use as inputs to other models: many AI systems take these vectors as starting features.\n",
      "- Dimensionality reduction for visualization: you can project high-dimensional embeddings down to 2D or 3D to see structure.\n",
      "\n",
      "A tiny, concrete example (very simplified):\n",
      "- Suppose we have words: cat, dog, carrot.\n",
      "- Their embeddings might be vectors like:\n",
      "  - cat: [0.8, 0.1, 0.2]\n",
      "  - dog: [0.79, 0.12, 0.22]\n",
      "  - carrot: [0.1, 0.9, -0.1]\n",
      "- Cat and dog vectors are close to each other (similar contexts like â€œpet,â€ â€œeat,â€ â€œpurrâ€), while carrot is far away (an object of a different context). The model didnâ€™t tell you what each number means, but the relative distances encode similarity.\n",
      "\n",
      "Common sizes and models (for intuition):\n",
      "- Word embeddings: often 50â€“300 dimensions.\n",
      "- Other embeddings (items, users, documents): also in the tens to hundreds of dimensions, depending on data and task.\n",
      "- Popular methods: Word2Vec, GloVe, fastText (for words); Doc2Vec (for documents); matrix factorization or neural approaches for items/users.\n",
      "\n",
      "Important caveats:\n",
      "- Interpretability is limited: you can say two vectors are similar, but individual dimensions usually donâ€™t have human-friendly meanings.\n",
      "- Bias and data quality matter: embeddings reflect the data theyâ€™re trained on; biased or biased data can lead to biased embeddings.\n",
      "- Not a magic fix: good embeddings help with similarity and prediction, but theyâ€™re just one part of a bigger system.\n",
      "\n",
      "In short, embeddings are a compact, numbers-based way to capture â€œwhat things are likeâ€ so that computers can reason about similarity and relationships between things. If you want, I can tailor the explanation to a specific domain (text, images, products, music, etc.).\n",
      "\n",
      "\n",
      "============================================================\n",
      "Topic: VECTOR DATABASES\n",
      "============================================================\n",
      "Streaming Output:\n",
      "\n",
      "Hereâ€™s a simple, beginner-friendly explanation of vector databases.\n",
      "\n",
      "What a vector database is\n",
      "- A vector database stores data as vectors (numbers in many dimensions) and helps you find items that are â€œcloseâ€ to a query in that space.\n",
      "- Itâ€™s built for similarity search: given a new item or a description, you want other items that are semantically similar, not just text-matched.\n",
      "\n",
      "What a vector is and what embeddings are\n",
      "- A vector is just a list of numbers. Each item (a document, an image, a product) can be turned into a vector.\n",
      "- An embedding is that numeric vector produced by a machine learning model. The model encodes meaning: items with similar meaning or content end up with similar vectors.\n",
      "\n",
      "How it differs from a traditional database\n",
      "- Traditional databases excel at exact matches and structured queries (like â€œfind rows where price = $10â€).\n",
      "- Vector databases excel at finding things that are conceptually similar, even if the wording or exact fields donâ€™t match. They measure â€œdistanceâ€ between vectors to judge similarity.\n",
      "\n",
      "How it works at a high level\n",
      "- Ingest: bring in items (texts, images, etc.) and store them with their metadata (title, date, tags).\n",
      "- Embed: convert each item into a vector using a model.\n",
      "- Index: build an index so searches are fast, even with millions of items. This often uses approximate methods to be efficient.\n",
      "- Query: convert your search (text or example item) into a vector, then find the nearest vectors in the index.\n",
      "- Return: show the most similar items, possibly filtered by metadata (language, category, date, etc.).\n",
      "\n",
      "Key terms youâ€™ll hear\n",
      "- Embedding: the numeric vector that represents an item.\n",
      "- Vector: the list of numbers for an item.\n",
      "- Similarity/distance: how close two vectors are. Common measures are cosine similarity and Euclidean distance.\n",
      "- Approximate Nearest Neighbor (ANN): a fast way to find near-by vectors, not always exact but usually good enough for huge data sets.\n",
      "- Index: the data structure that makes searching fast (e.g., HNSW, IVF, etc.).\n",
      "\n",
      "What you can use it for\n",
      "- Semantic search: ask a question in everyday language and get results that match the meaning, not just exact keywords.\n",
      "- Recommendations: show items that are similar to what a user liked.\n",
      "- Image/audio similarity: find visually or auditorily similar media.\n",
      "- Data integration: quickly locate related records across unstructured data (documents, emails, notes).\n",
      "\n",
      "Pros and challenges (quick view)\n",
      "- Pros: scalable semantic search, fast retrieval on big data, handles unstructured data well.\n",
      "- Challenges: you need good embeddings; results depend on the model; updating data can require re-embedding; costs can grow with data size.\n",
      "\n",
      "Simple analogy\n",
      "- Imagine a giant map where each item is a star. Similar items are neighbors. Youâ€™re allowed to plot a new point (your query) somewhere on the map, and the system quickly points you to the nearest stars. You can also filter by regions (metadata) to narrow down results.\n",
      "\n",
      "A tiny starter guide (5 easy steps)\n",
      "1) Choose your data: e.g., a set of article documents.\n",
      "2) Pick an embedding model: a text model that turns each article into a vector.\n",
      "3) Store vectors in a vector DB along with metadata (title, date, tag).\n",
      "4) When you search, embed your query into a vector and ask the DB for nearest neighbors.\n",
      "5) Show the top results, with optional filters (language, topic, date).\n",
      "\n",
      "Common tools (quick sense of options)\n",
      "- Managed services: Pinecone, Weaviate (also handles metadata and types), Chroma.\n",
      "- Open-source libraries / runtimes: Milvus, FAISS (library, not a hosted service), Vespa.\n",
      "- Most tools support text, images, or other data types, and many offer easy APIs.\n",
      "\n",
      "When to use a vector database\n",
      "- You want results based on meaning rather than exact keyword matching.\n",
      "- Youâ€™re dealing with large amounts of unstructured data (texts, images, audio) and need scalable search or recommendations.\n",
      "- Traditional exact-match queries arenâ€™t giving good results for your use case.\n",
      "\n",
      "If youâ€™d like, tell me your data type (text, images, products, etc.) and a sample task (semantic search, recommendations, etc.), and I can suggest a concrete beginner-friendly setup and a tiny example.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for topic in topics:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Topic: {topic.upper()}\")\n",
    "    print('='*60)\n",
    "\n",
    "    print(\"Streaming Output:\\n\")\n",
    "\n",
    "    for chunk in chain.stream({\"topic\": topic}):\n",
    "        print(chunk, end=\"\", flush=True)\n",
    "\n",
    "    print(\"\\n\")  # spacing after each topic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“ INTERMEDIATE: Batch Processing\n",
    "\n",
    "Process multiple inputs efficiently using `.batch()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. RAG:\n",
      "   RAG stands for Retrieval-Augmented Generation. Itâ€™s a way for a language model to answer questions b...\n",
      "\n",
      "2. LCEL:\n",
      "   Iâ€™m not sure which LCEL you mean, because the acronym can stand for different things in different fi...\n",
      "\n",
      "3. LANGCHAIN AGENTS:\n",
      "   Hereâ€™s a beginner-friendly way to understand LangChain agents.\n",
      "\n",
      "What is a LangChain agent?\n",
      "- Itâ€™s a ...\n"
     ]
    }
   ],
   "source": [
    "# Batch process multiple topics at once\n",
    "topics_batch = [\n",
    "    {\"topic\": \"RAG\"},\n",
    "    {\"topic\": \"LCEL\"},\n",
    "    {\"topic\": \"LangChain agents\"}\n",
    "]\n",
    "\n",
    "# Batch processing is more efficient than calling invoke() multiple times\n",
    "results = chain.batch(topics_batch)\n",
    "\n",
    "# Print results\n",
    "for i, (input_dict, result) in enumerate(zip(topics_batch, results), 1):\n",
    "    print(f\"\\n{i}. {input_dict['topic'].upper()}:\")\n",
    "    print(f\"   {result[:100]}...\")  # Print first 100 chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def run_batch():\n",
    "    async for event in chain.astream_batch(topics_batch):\n",
    "        print(event)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01masyncio\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.13.2-windows-x86_64-none\\Lib\\asyncio\\runners.py:191\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(main, debug, loop_factory)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[32m    162\u001b[39m \n\u001b[32m    163\u001b[39m \u001b[33;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    187\u001b[39m \u001b[33;03m    asyncio.run(main())\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m events._get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    190\u001b[39m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    192\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    194\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug=debug, loop_factory=loop_factory) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[32m    195\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m runner.run(main)\n",
      "\u001b[31mRuntimeError\u001b[39m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "asyncio.run(run_batch())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RunnableSequence' object has no attribute 'astream_batch'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m run_batch()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mrun_batch\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_batch\u001b[39m():\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m \u001b[43mchain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastream_batch\u001b[49m(topics_batch):\n\u001b[32m      3\u001b[39m         \u001b[38;5;28mprint\u001b[39m(event)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\UltimateRAG\\simple-rag-langchain\\.venv\\Lib\\site-packages\\pydantic\\main.py:1026\u001b[39m, in \u001b[36mBaseModel.__getattr__\u001b[39m\u001b[34m(self, item)\u001b[39m\n\u001b[32m   1023\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[32m   1024\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1025\u001b[39m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'RunnableSequence' object has no attribute 'astream_batch'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen genericpath>:113: RuntimeWarning: coroutine 'run_batch' was never awaited\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "await run_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RunnableSequence' object has no attribute 'astream_batch'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnest_asyncio\u001b[39;00m\n\u001b[32m      2\u001b[39m nest_asyncio.apply()\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\UltimateRAG\\simple-rag-langchain\\.venv\\Lib\\site-packages\\nest_asyncio.py:30\u001b[39m, in \u001b[36m_patch_asyncio.<locals>.run\u001b[39m\u001b[34m(main, debug)\u001b[39m\n\u001b[32m     28\u001b[39m task = asyncio.ensure_future(main)\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task.done():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\UltimateRAG\\simple-rag-langchain\\.venv\\Lib\\site-packages\\nest_asyncio.py:98\u001b[39m, in \u001b[36m_patch_loop.<locals>.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f.done():\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     97\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mEvent loop stopped before Future completed.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.13.2-windows-x86_64-none\\Lib\\asyncio\\futures.py:199\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;28mself\u001b[39m.__log_traceback = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception.with_traceback(\u001b[38;5;28mself\u001b[39m._exception_tb)\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.13.2-windows-x86_64-none\\Lib\\asyncio\\tasks.py:304\u001b[39m, in \u001b[36mTask.__step_run_and_handle_result\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    300\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    301\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    302\u001b[39m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[32m    303\u001b[39m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m         result = \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    305\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    306\u001b[39m         result = coro.throw(exc)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mrun_batch\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_batch\u001b[39m():\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m \u001b[43mchain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastream_batch\u001b[49m(topics_batch):\n\u001b[32m      3\u001b[39m         \u001b[38;5;28mprint\u001b[39m(event)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\UltimateRAG\\simple-rag-langchain\\.venv\\Lib\\site-packages\\pydantic\\main.py:1026\u001b[39m, in \u001b[36mBaseModel.__getattr__\u001b[39m\u001b[34m(self, item)\u001b[39m\n\u001b[32m   1023\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[32m   1024\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1025\u001b[39m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'RunnableSequence' object has no attribute 'astream_batch'"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "asyncio.run(run_batch())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. RAG:\n",
      "RAG stands for Retrieval-Augmented Generation. In plain terms, itâ€™s a way for an AI to answer questions by first looking up the right information in a library and then writing the answer using what it ...\n",
      "\n",
      "\n",
      "2. LCEL:\n",
      "Iâ€™m not sure which LCEL you meanâ€”there are different things that use that acronym in different fields. Could you tell me the full form of LCEL or the context (e.g., computer science, electronics, math ...\n",
      "\n",
      "\n",
      "3. LANGCHAIN AGENTS:\n",
      "Hereâ€™s a beginner-friendly way to think about LangChain agents.\n",
      "\n",
      "What is a LangChain agent?\n",
      "- An agent is like a smart assistant powered by a language model (LLM) that can use tools to complete a task ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "async def run_batch():\n",
    "    results = await chain.abatch(topics_batch)  # async batch, no streaming\n",
    "\n",
    "    for i, (inp, res) in enumerate(zip(topics_batch, results), 1):\n",
    "        print(f\"\\n{i}. {inp['topic'].upper()}:\")\n",
    "        print(res[:200], \"...\\n\")  # print first 200 chars\n",
    "\n",
    "# In a notebook\n",
    "await run_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"comparison\"></a>\n",
    "## 6. LangChain vs Traditional ML Pipelines ğŸ†š\n",
    "\n",
    "### ğŸ”° BEGINNER: Key Differences\n",
    "\n",
    "| Aspect | Traditional ML | LangChain |\n",
    "|--------|---------------|------------|\n",
    "| **Setup** | Complex, manual | Pre-built components |\n",
    "| **Integration** | Write custom code | Use existing integrations |\n",
    "| **Composability** | Difficult to chain | Easy with LCEL |\n",
    "| **Debugging** | Manual logging | Built-in callbacks |\n",
    "| **Prototyping** | Slow | Very fast |\n",
    "| **Code Reuse** | Limited | High |\n",
    "\n",
    "### Example: Building a Q&A System\n",
    "\n",
    "#### Without LangChain (50+ lines):\n",
    "```python\n",
    "import openai\n",
    "import PyPDF2\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# 1. Load PDF manually\n",
    "def load_pdf(file_path):\n",
    "    reader = PyPDF2.PdfReader(file_path)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "# 2. Split text manually\n",
    "def split_text(text, chunk_size=1000):\n",
    "    chunks = []\n",
    "    for i in range(0, len(text), chunk_size):\n",
    "        chunks.append(text[i:i+chunk_size])\n",
    "    return chunks\n",
    "\n",
    "# 3. Create embeddings manually\n",
    "def create_embeddings(chunks):\n",
    "    embeddings = []\n",
    "    for chunk in chunks:\n",
    "        response = openai.Embedding.create(\n",
    "            input=chunk,\n",
    "            model=\"text-embedding-ada-002\"\n",
    "        )\n",
    "        embeddings.append(response['data'][0]['embedding'])\n",
    "    return np.array(embeddings)\n",
    "\n",
    "# 4. Create vector store manually\n",
    "def create_vector_store(embeddings):\n",
    "    dimension = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatL2(dimension)\n",
    "    index.add(embeddings)\n",
    "    return index\n",
    "\n",
    "# 5. Search manually\n",
    "def search(query, index, chunks):\n",
    "    query_embedding = openai.Embedding.create(\n",
    "        input=query,\n",
    "        model=\"text-embedding-ada-002\"\n",
    "    )['data'][0]['embedding']\n",
    "    \n",
    "    distances, indices = index.search(\n",
    "        np.array([query_embedding]), k=3\n",
    "    )\n",
    "    return [chunks[i] for i in indices[0]]\n",
    "\n",
    "# 6. Generate answer manually\n",
    "def generate_answer(query, context):\n",
    "    prompt = f\"Context: {context}\\n\\nQuestion: {query}\\n\\nAnswer:\"\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response['choices'][0]['message']['content']\n",
    "\n",
    "# Use it:\n",
    "text = load_pdf(\"document.pdf\")\n",
    "chunks = split_text(text)\n",
    "embeddings = create_embeddings(chunks)\n",
    "index = create_vector_store(embeddings)\n",
    "relevant_chunks = search(\"What is RAG?\", index, chunks)\n",
    "answer = generate_answer(\"What is RAG?\", \" \".join(relevant_chunks))\n",
    "```\n",
    "\n",
    "#### With LangChain (10 lines!):\n",
    "```python\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# Load, split, embed, and store\n",
    "docs = PyPDFLoader(\"document.pdf\").load()\n",
    "chunks = RecursiveCharacterTextSplitter(chunk_size=1000).split_documents(docs)\n",
    "vectorstore = FAISS.from_documents(chunks, OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Build RAG chain\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Context: {context}\\n\\nQuestion: {question}\\n\\nAnswer:\"\n",
    ")\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt | ChatOpenAI() | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Use it:\n",
    "answer = chain.invoke(\"What is RAG?\")\n",
    "```\n",
    "\n",
    "**50+ lines â†’ 10 lines!** ğŸ‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"summary\"></a>\n",
    "## 7. Summary & Next Steps ğŸ“\n",
    "\n",
    "### ğŸ‰ What You Learned\n",
    "\n",
    "âœ… **LangChain** is a framework that simplifies building LLM applications\n",
    "\n",
    "âœ… **Architecture** is modular: loaders, splitters, embeddings, vector stores, chains\n",
    "\n",
    "âœ… **Documents** contain `page_content` (text) and `metadata` (information about the text)\n",
    "\n",
    "âœ… **LCEL** uses the `|` operator to chain components together\n",
    "\n",
    "âœ… **Chains** connect multiple components to create complex workflows\n",
    "\n",
    "âœ… LangChain **dramatically reduces code** compared to manual implementations\n",
    "\n",
    "### ğŸ”° For Beginners\n",
    "You now understand:\n",
    "- What LangChain is and why it's useful\n",
    "- How to set up your environment\n",
    "- Basic concepts: Documents and Chains\n",
    "- How to make your first LLM call\n",
    "\n",
    "### ğŸ“ For Intermediate Learners\n",
    "You now understand:\n",
    "- LangChain's package structure (1.0+ reorganization)\n",
    "- LCEL internals and advantages\n",
    "- Metadata usage for filtering and citation\n",
    "- Batch processing for efficiency\n",
    "\n",
    "### ğŸ“š Next Notebooks\n",
    "\n",
    "1. **Notebook 02**: Document Loaders (PDF, CSV, JSON, HTML)\n",
    "2. **Notebook 03**: Text Splitting Strategies\n",
    "3. **Notebook 04**: Embeddings and Vector Representations\n",
    "4. **Notebook 05**: Vector Stores (FAISS, Chroma)\n",
    "5. **Notebook 06**: Retrieval Strategies\n",
    "6. **Notebook 07**: Complete RAG Pipeline\n",
    "\n",
    "### ğŸ’¡ Practice Exercises\n",
    "\n",
    "Before moving to the next notebook, try these:\n",
    "\n",
    "1. **Easy**: Create 5 Documents about different topics with meaningful metadata\n",
    "2. **Medium**: Build a chain that takes a topic and generates a haiku about it\n",
    "3. **Advanced**: Create a chain that summarizes text in different styles (formal, casual, technical)\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ Additional Resources\n",
    "\n",
    "- [Official LangChain Documentation](https://python.langchain.com/docs/)\n",
    "- [LCEL Guide](https://python.langchain.com/docs/expression_language/)\n",
    "- [LangChain GitHub](https://github.com/langchain-ai/langchain)\n",
    "\n",
    "---\n",
    "\n",
    "**Ready for more? Continue to Notebook 02: Document Loaders! ğŸš€**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
